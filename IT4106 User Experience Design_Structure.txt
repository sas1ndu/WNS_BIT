Overall Exam Structure:

The IT4106 User Experience Design exam consistently consists of two parts, typically administered together within a set timeframe (e.g., 2 hours for both parts in 2023, or 1 hour for each part previously ).



Part 1: Multiple Choice Questions (MCQ)

Comprises 25 questions.


Each question has 5 choices, and critically, there can be one or more correct answers.


All questions carry equal marks.


There's a penalty for incorrect responses to discourage guessing. The penalty system has varied slightly (e.g., marks from 0 to +2 in 2021, and from -1 to +1 with a minimum of 0 per question in 2022 and 2023 ).


Answers are marked on a special machine-readable answer sheet.



Calculators are not allowed.




Part 2: Structured Question Paper

Typically contains 2 main questions, which may have multiple sub-parts.


Marks for questions/sub-parts are not always equal.

Answers are to be written in English in the space provided on the question paper itself.


Calculators are not allowed.


Common Content Areas and Themes Tested:

Across both MCQ and Structured Question parts, the exams cover a broad range of topics from the User Experience Design syllabus. Key areas frequently tested include:

Foundations of HCI and UX:

HCI Paradigms: Understanding the different ways of viewing reality in HCI (e.g., Paradigm 1, 2, 3 as questioned in 2021 Part 2 ).
UXD vs. UID: Distinguishing between User Experience Design and User Interface Design.
User-Centered Design (UCD): Defining UCD, its importance, and its process (Understand → Specify Requirement → Design Solutions → Evaluate against requirements).




Double Diamond Process: Knowing the four stages in order (Discover, Define, Develop, Deliver).


Good Design Principles: Identifying characteristics of good design (iterative, user-focused, functional).
Affordances: Understanding their role in communicating function.
Cognitive Aspects:

Cognition Definition & Processes: Higher-level brain functions.

Experiential vs. Reflective Cognition: Distinguishing between intuitive reactions and effortful thought, with examples.




Specific Cognitive Processes: Attention (focusing on stimuli)  and Perception (acquiring information via senses).




Cognitive Frameworks:
Human Processor Model (stages: Encoding → Comparison → Response selection → Response execution).


Mental Models (influenced by background, guide perception, not static).


External Cognition (explaining processes with external representations like images, multimedia).
Distributed Cognition, Co-presence.

Gulf of Execution/Evaluation.
Affective Computing: Computers recognizing and expressing emotions.
Interaction Design & Interface Types:

Interaction Types: Instructing, Conversing, Exploring, Responding, Manipulating (and identifying the most recent, like "Responding").




Specific Interfaces: Haptic (tactile feedback), Contextual Menus (Pop-up, Pie-menu), Augmented Reality (blends digital with real world), Virtual Reality (replaces real world), Pen-based interfaces, Tangible interfaces.




Data Gathering:

Importance of Understanding Users: Considering age, gender, education, cultural background.
Key Issues: Goal setting, identifying participants, data collector-provider relationship.
Sampling Techniques: Non-probability (Snowball, Convenience, Purposive).


Triangulation: Using multiple sources/methods/theories for data verification.


Engaging Users with Probes: Types like design, technology, and provocative probes.
Contextual Inquiry: Understanding users in their natural environment, shifting power dynamic.
User Research Methods: Distinguishing between methods used with or without an artifact.
Data Analysis:

Qualitative vs. Quantitative Data: Qualitative (words, images, patterns, stories), Quantitative (numerical, averages, ratios).



Qualitative Analysis Approaches: Thematic analysis, data categorization, analyzing critical incidents.




Analytic Frameworks: Discourse analysis (focus on word meaning), Content analysis (classifying into themes, frequency), Conversation analysis, Grounded theory.



Prototyping:

Fidelity of Prototypes: Level of detail and functionality, look-and-feel.
Conceptual Models: Core components (metaphors, concepts exposed to users, relationships, mappings).
Low-Fidelity Prototypes: Paper-based storyboards, quick revisions, good for communication and concept evaluation.


High-Fidelity Prototypes: Close resemblance to final product, allows detailed usability testing, stakeholder buy-in, clearer developer specifications.

Conceptual vs. Concrete Design: Conceptual (what people can do), Concrete (layout, navigation details).
Evaluation:

Purpose: Evaluating designs without users (heuristic, walkthroughs, predictive modeling).

Formative Evaluation: Conducted during design to meet user needs.
Evaluation Environments: Lab, natural setting/in-the-wild, remote setting.
Heuristic Evaluation: Expert review against usability principles (Nielsen's 10 heuristics are frequently cited).




Walkthroughs: Cognitive (simulating user problem-solving, ease of learning)  and Pluralistic (involving users, developers, researchers).




A/B Testing: Comparing two design versions with different user groups.


Methods for Controlled Settings with Users: Usability testing, experiments.
Online Surveys: For evaluating user experience and help system effectiveness.
Design Thinking: A modern approach to involve users (Empathize, Define, Ideate, Prototype, Test). "Wicked problems" are identified as ill-defined or unknown problems in this context.



Key Takeaways from the Analysis:

Breadth over Depth in MCQs: The MCQs test a wide range of terminologies, definitions, process stages, and the ability to differentiate between concepts. The "one or more correct answers" format requires careful reading.
Application and Explanation in Structured Questions: Part 2 requires students to define concepts, explain differences, apply methods to scenarios, and justify their choices.
Recurring Core Concepts: The Double Diamond, UCD, cognitive processes, prototyping fidelities, various data gathering & analysis techniques, and evaluation methods (especially heuristic evaluation, walkthroughs, A/B testing) are staples.
Practical Scenarios: Part 2 often uses scenarios to assess the student's ability to select and justify appropriate UX methods.
Diagrams: Occasionally, diagrams are expected or referred to in structured answers (e.g., for mental/conceptual models, design thinking).
The exams appear to be comprehensive, testing both theoretical knowledge and the ability to apply concepts to practical UX design situations.
