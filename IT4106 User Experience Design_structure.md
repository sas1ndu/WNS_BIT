# Overall Exam Structure:

The IT4106 User Experience Design exam consistently consists of two parts, typically administered together within a set timeframe (e.g., 2 hours for both parts in 2023, or 1 hour for each part previously).

## Part 1: Multiple Choice Questions (MCQ)

-   Comprises 25 questions.
-   Each question has 5 choices, and **critically, there can be one or more correct answers.**
-   All questions carry equal marks.
-   There's a penalty for incorrect responses to discourage guessing. The penalty system has varied slightly (e.g., marks from 0 to +2 in 2021, and from -1 to +1 with a minimum of 0 per question in 2022 and 2023).
-   Answers are marked on a special machine-readable answer sheet.
-   Calculators are **not allowed**.

## Part 2: Structured Question Paper

-   Typically contains 2 main questions, which may have multiple sub-parts.
-   Marks for questions/sub-parts are not always equal.
-   Answers are to be written in English in the space provided on the question paper itself.
-   Calculators are **not allowed**.

## Common Content Areas and Themes Tested:

Across both MCQ and Structured Question parts, the exams cover a broad range of topics from the User Experience Design syllabus. Key areas frequently tested include:

-   **Foundations of HCI and UX:**
    -   **HCI Paradigms:** Understanding the different ways of viewing reality in HCI (e.g., Paradigm 1, 2, 3 as questioned in 2021 Part 2).
    -   **UXD vs. UID:** Distinguishing between User Experience Design and User Interface Design.
    -   **User-Centered Design (UCD):** Defining UCD, its importance, and its process (Understand → Specify Requirement → Design Solutions → Evaluate against requirements).
    -   **Double Diamond Process:** Knowing the four stages in order (Discover, Define, Develop, Deliver).
    -   **Good Design Principles:** Identifying characteristics of good design (iterative, user-focused, functional).
    -   **Affordances:** Understanding their role in communicating function.

-   **Cognitive Aspects:**
    -   **Cognition Definition & Processes:** Higher-level brain functions.
    -   **Experiential vs. Reflective Cognition:** Distinguishing between intuitive reactions and effortful thought, with examples.
    -   **Specific Cognitive Processes:** Attention (focusing on stimuli) and Perception (acquiring information via senses).
    -   **Cognitive Frameworks:**
        -   **Human Processor Model** (stages: Encoding → Comparison → Response selection → Response execution).
        -   **Mental Models** (influenced by background, guide perception, not static).
        -   **External Cognition** (explaining processes with external representations like images, multimedia).
        -   **Distributed Cognition, Co-presence.**
        -   **Gulf of Execution/Evaluation.**
    -   **Affective Computing:** Computers recognizing and expressing emotions.

-   **Interaction Design & Interface Types:**
    -   **Interaction Types:** Instructing, Conversing, Exploring, Responding, Manipulating (and identifying the most recent, like "Responding").
    -   **Specific Interfaces:** Haptic (tactile feedback), Contextual Menus (Pop-up, Pie-menu), Augmented Reality (blends digital with real world), Virtual Reality (replaces real world), Pen-based interfaces, Tangible interfaces.

-   **Data Gathering:**
    -   **Importance of Understanding Users:** Considering age, gender, education, cultural background.
    -   **Key Issues:** Goal setting, identifying participants, data collector-provider relationship.
    -   **Sampling Techniques:** Non-probability (Snowball, Convenience, Purposive).
    -   **Triangulation:** Using multiple sources/methods/theories for data verification.
    -   **Engaging Users with Probes:** Types like design, technology, and provocative probes.
    -   **Contextual Inquiry:** Understanding users in their natural environment, shifting power dynamic.
    -   **User Research Methods:** Distinguishing between methods used with or without an artifact.

-   **Data Analysis:**
    -   **Qualitative vs. Quantitative Data:** Qualitative (words, images, patterns, stories), Quantitative (numerical, averages, ratios).
    -   **Qualitative Analysis Approaches:** Thematic analysis, data categorization, analyzing critical incidents.
    -   **Analytic Frameworks:** Discourse analysis (focus on word meaning), Content analysis (classifying into themes, frequency), Conversation analysis, Grounded theory.

-   **Prototyping:**
    -   **Fidelity of Prototypes:** Level of detail and functionality, look-and-feel.
    -   **Conceptual Models:** Core components (metaphors, concepts exposed to users, relationships, mappings).
    -   **Low-Fidelity Prototypes:** Paper-based storyboards, quick revisions, good for communication and concept evaluation.
    -   **High-Fidelity Prototypes:** Close resemblance to final product, allows detailed usability testing, stakeholder buy-in, clearer developer specifications.
    -   **Conceptual vs. Concrete Design:** Conceptual (what people can do), Concrete (layout, navigation details).

-   **Evaluation:**
    -   **Purpose:** Evaluating designs without users (heuristic, walkthroughs, predictive modeling).
    -   **Formative Evaluation:** Conducted during design to meet user needs.
    -   **Evaluation Environments:** Lab, natural setting/in-the-wild, remote setting.
    -   **Heuristic Evaluation:** Expert review against usability principles (Nielsen's 10 heuristics are frequently cited).
    -   **Walkthroughs:** Cognitive (simulating user problem-solving, ease of learning) and Pluralistic (involving users, developers, researchers).
    -   **A/B Testing:** Comparing two design versions with different user groups.
    -   **Methods for Controlled Settings with Users:** Usability testing, experiments.
    -   **Online Surveys:** For evaluating user experience and help system effectiveness.

-   **Design Thinking:** A modern approach to involve users (Empathize, Define, Ideate, Prototype, Test). "Wicked problems" are identified as ill-defined or unknown problems in this context.

## Key Takeaways from the Analysis:

-   **Breadth over Depth in MCQs:** The MCQs test a wide range of terminologies, definitions, process stages, and the ability to differentiate between concepts. The "one or more correct answers" format requires careful reading.
-   **Application and Explanation in Structured Questions:** Part 2 requires students to define concepts, explain differences, apply methods to scenarios, and justify their choices.
-   **Recurring Core Concepts:** The Double Diamond, UCD, cognitive processes, prototyping fidelities, various data gathering & analysis techniques, and evaluation methods (especially heuristic evaluation, walkthroughs, A/B testing) are staples.
-   **Practical Scenarios:** Part 2 often uses scenarios to assess the student's ability to select and justify appropriate UX methods.
-   **Diagrams:** Occasionally, diagrams are expected or referred to in structured answers (e.g., for mental/conceptual models, design thinking).

The exams appear to be comprehensive, testing both theoretical knowledge and the ability to apply concepts to practical UX design situations.
